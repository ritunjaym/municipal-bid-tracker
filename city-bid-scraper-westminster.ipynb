{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyONw86XSYYkCoSjN2JzOXKo"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# City Bid Tracker - Westminster\n","\n","Automated scraper for public procurement opportunities from Westminster's official website.\n","\n","## Purpose\n","Helps contractors and vendors discover bidding opportunities by extracting:\n","- RFP numbers and titles\n","- Starting and closing dates\n","- Bid status information\n","- Direct links to full documentation\n","\n","## Setup & Usage\n","1. Run the dependency installation cell\n","2. Execute the crawler class definition\n","3. Run the final execution cell\n","4. CSV file will be automatically downloaded\n","\n","## Output\n","Creates `westminster_bids.csv` with all current bid opportunities.\n","\n","## Technical Notes\n","This crawler implements enhanced anti-blocking measures due to the website's protection systems, including realistic browser headers and retry logic for access denied responses."],"metadata":{"id":"enRsWtjEImfz"}},{"cell_type":"code","source":["!pip install selenium webdriver_manager pandas\n","# Install Chrome and ChromeDriver\n","!apt-get update\n","!apt install chromium-chromedriver"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CYjcMQfIUfzj","executionInfo":{"status":"ok","timestamp":1739216674569,"user_tz":480,"elapsed":11706,"user":{"displayName":"Ritunjay Murali","userId":"07921326813984298862"}},"outputId":"778055fc-e7ad-4d2d-c053-6ef307f1e483"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: selenium in /usr/local/lib/python3.11/dist-packages (4.28.1)\n","Requirement already satisfied: webdriver_manager in /usr/local/lib/python3.11/dist-packages (4.0.2)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n","Requirement already satisfied: urllib3<3,>=1.26 in /usr/local/lib/python3.11/dist-packages (from urllib3[socks]<3,>=1.26->selenium) (2.3.0)\n","Requirement already satisfied: trio~=0.17 in /usr/local/lib/python3.11/dist-packages (from selenium) (0.28.0)\n","Requirement already satisfied: trio-websocket~=0.9 in /usr/local/lib/python3.11/dist-packages (from selenium) (0.11.1)\n","Requirement already satisfied: certifi>=2021.10.8 in /usr/local/lib/python3.11/dist-packages (from selenium) (2025.1.31)\n","Requirement already satisfied: typing_extensions~=4.9 in /usr/local/lib/python3.11/dist-packages (from selenium) (4.12.2)\n","Requirement already satisfied: websocket-client~=1.8 in /usr/local/lib/python3.11/dist-packages (from selenium) (1.8.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from webdriver_manager) (2.32.3)\n","Requirement already satisfied: python-dotenv in /usr/local/lib/python3.11/dist-packages (from webdriver_manager) (1.0.1)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from webdriver_manager) (24.2)\n","Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (1.26.4)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n","Requirement already satisfied: attrs>=23.2.0 in /usr/local/lib/python3.11/dist-packages (from trio~=0.17->selenium) (25.1.0)\n","Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.11/dist-packages (from trio~=0.17->selenium) (2.4.0)\n","Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from trio~=0.17->selenium) (3.10)\n","Requirement already satisfied: outcome in /usr/local/lib/python3.11/dist-packages (from trio~=0.17->selenium) (1.3.0.post0)\n","Requirement already satisfied: sniffio>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from trio~=0.17->selenium) (1.3.1)\n","Requirement already satisfied: wsproto>=0.14 in /usr/local/lib/python3.11/dist-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n","Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in /usr/local/lib/python3.11/dist-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->webdriver_manager) (3.4.1)\n","Requirement already satisfied: h11<1,>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n","Hit:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n","Hit:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n","Hit:3 http://security.ubuntu.com/ubuntu jammy-security InRelease\n","Hit:4 http://archive.ubuntu.com/ubuntu jammy InRelease\n","Hit:5 http://archive.ubuntu.com/ubuntu jammy-updates InRelease\n","Hit:6 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n","Hit:7 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n","Hit:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n","Hit:9 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n","Hit:10 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n","Reading package lists... Done\n","W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n","Reading package lists... Done\n","Building dependency tree... Done\n","Reading state information... Done\n","chromium-chromedriver is already the newest version (1:85.0.4183.83-0ubuntu2.22.04.1).\n","0 upgraded, 0 newly installed, 0 to remove and 24 not upgraded.\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UTAeds5eTZJm"},"outputs":[],"source":["from selenium import webdriver\n","from selenium.webdriver.common.by import By\n","from selenium.webdriver.support.ui import WebDriverWait\n","from selenium.webdriver.support import expected_conditions as EC\n","from selenium.webdriver.chrome.service import Service\n","from selenium.webdriver.chrome.options import Options\n","from webdriver_manager.chrome import ChromeDriverManager\n","from datetime import datetime\n","import csv\n","import os\n","import time\n","from google.colab import files\n","import random\n","\n","class WestminsterBidsCrawler:\n","    def __init__(self):\n","        self.base_url = \"https://www.westminster-ca.gov/departments/advanced-components/list-detail-pages/rfp-posts-list\"\n","        self.output_file = \"westminster_bids.csv\"\n","        self.fieldnames = [\n","            \"RFP Number\",\n","            \"Title\",\n","            \"Starting Date\",\n","            \"Closing Date\",\n","            \"Status\",\n","            \"Details URL\",\n","            \"Last Updated\"\n","        ]\n","        self.max_retries = 3\n","        self.setup_driver()\n","\n","    def setup_driver(self):\n","        \"\"\"Setup Chrome driver with enhanced options to avoid blocking\"\"\"\n","        chrome_options = Options()\n","        chrome_options.add_argument('--headless')\n","        chrome_options.add_argument('--no-sandbox')\n","        chrome_options.add_argument('--disable-dev-shm-usage')\n","        chrome_options.add_argument('--disable-gpu')\n","        chrome_options.add_argument('--window-size=1920,1080')\n","\n","        # Add realistic browser headers\n","        chrome_options.add_argument('--user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36')\n","        chrome_options.add_argument('--accept-language=en-US,en;q=0.9')\n","        chrome_options.add_argument('--disable-blink-features=AutomationControlled')\n","\n","        # Additional headers to look more like a real browser\n","        chrome_options.add_experimental_option(\"excludeSwitches\", [\"enable-automation\"])\n","        chrome_options.add_experimental_option('useAutomationExtension', False)\n","\n","        try:\n","            print(\"Attempting to use system chromedriver...\")\n","            self.driver = webdriver.Chrome(options=chrome_options)\n","        except Exception as e:\n","            print(f\"System chromedriver failed: {str(e)}\")\n","            print(\"Attempting to use ChromeDriverManager...\")\n","            service = Service(ChromeDriverManager().install())\n","            self.driver = webdriver.Chrome(service=service, options=chrome_options)\n","\n","        # Set page load timeout\n","        self.driver.set_page_load_timeout(30)\n","\n","        # Add additional headers via CDP\n","        self.driver.execute_cdp_cmd('Network.setUserAgentOverride', {\n","            \"userAgent\": 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'\n","        })\n","\n","        self.wait = WebDriverWait(self.driver, 15)  # Increased wait time\n","        print(\"Chrome driver initialized successfully\")\n","\n","    def random_delay(self):\n","        \"\"\"Add random delay between actions to appear more human-like\"\"\"\n","        time.sleep(random.uniform(2, 5))\n","\n","    def parse_bid_item(self, row):\n","        \"\"\"Parse individual bid listing row\"\"\"\n","        try:\n","            print(\"\\nParsing new row...\")\n","            bid_data = {\n","                \"RFP Number\": \"\",\n","                \"Title\": \"\",\n","                \"Starting Date\": \"\",\n","                \"Closing Date\": \"\",\n","                \"Status\": \"\",\n","                \"Details URL\": \"\",\n","                \"Last Updated\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n","            }\n","\n","            cells = row.find_elements(By.TAG_NAME, \"td\")\n","            print(f\"Found {len(cells)} cells in row\")\n","\n","            if len(cells) >= 5:\n","                bid_data[\"RFP Number\"] = cells[0].text.strip()\n","\n","                try:\n","                    title_link = cells[1].find_element(By.TAG_NAME, \"a\")\n","                    bid_data[\"Title\"] = title_link.text.strip()\n","                    bid_data[\"Details URL\"] = title_link.get_attribute(\"href\")\n","                except Exception as e:\n","                    print(f\"Error extracting title/URL: {str(e)}\")\n","\n","                bid_data[\"Starting Date\"] = cells[2].text.strip()\n","                bid_data[\"Closing Date\"] = cells[3].text.strip()\n","                bid_data[\"Status\"] = cells[4].text.strip()\n","\n","                print(f\"Parsed bid: {bid_data['Title']}\")\n","                return bid_data if bid_data[\"Title\"] else None\n","\n","            return None\n","\n","        except Exception as e:\n","            print(f\"Error parsing bid item: {str(e)}\")\n","            return None\n","\n","    def setup_csv(self):\n","        \"\"\"Create or verify CSV file with headers\"\"\"\n","        try:\n","            if not os.path.exists(self.output_file):\n","                with open(self.output_file, 'w', newline='', encoding='utf-8') as f:\n","                    writer = csv.DictWriter(f, fieldnames=self.fieldnames)\n","                    writer.writeheader()\n","                print(f\"Created new CSV file: {self.output_file}\")\n","            else:\n","                print(f\"CSV file already exists: {self.output_file}\")\n","        except Exception as e:\n","            print(f\"Error setting up CSV: {str(e)}\")\n","\n","    def get_page_with_retry(self):\n","        \"\"\"Attempt to load the page with retries\"\"\"\n","        for attempt in range(self.max_retries):\n","            try:\n","                print(f\"\\nAttempt {attempt + 1} to load page...\")\n","                self.driver.get(self.base_url)\n","                self.random_delay()\n","\n","                # Check for access denied\n","                if \"Access Denied\" in self.driver.page_source:\n","                    print(\"Access Denied detected, retrying...\")\n","                    continue\n","\n","                print(\"Page loaded successfully\")\n","                return True\n","            except Exception as e:\n","                print(f\"Error loading page: {str(e)}\")\n","                if attempt < self.max_retries - 1:\n","                    wait_time = (attempt + 1) * 5\n","                    print(f\"Waiting {wait_time} seconds before retry...\")\n","                    time.sleep(wait_time)\n","                continue\n","        return False\n","\n","    def get_bid_listings(self):\n","        \"\"\"Fetch and parse all bid listings\"\"\"\n","        try:\n","            if not self.get_page_with_retry():\n","                print(\"Failed to load page after all retries\")\n","                return []\n","\n","            print(\"Looking for bid table...\")\n","            table = None\n","\n","            # Try multiple selectors with explicit wait\n","            try:\n","                table = self.wait.until(\n","                    EC.presence_of_element_located((By.CSS_SELECTOR, \"table.responsive-table-data-mb\"))\n","                )\n","            except Exception as e:\n","                print(f\"Error finding table: {str(e)}\")\n","                print(\"Page source preview:\")\n","                print(self.driver.page_source[:500])\n","                return []\n","\n","            # Find all bid rows\n","            rows = table.find_elements(By.XPATH, \".//tbody/tr\")\n","            print(f\"Found {len(rows)} rows in table\")\n","\n","            bids = []\n","            for row in rows:\n","                bid_data = self.parse_bid_item(row)\n","                if bid_data:\n","                    bids.append(bid_data)\n","                self.random_delay()\n","\n","            print(f\"Successfully parsed {len(bids)} bids\")\n","            return bids\n","\n","        except Exception as e:\n","            print(f\"Error fetching bid listings: {str(e)}\")\n","            return []\n","\n","    def save_bids(self, bids):\n","        \"\"\"Save bid data to CSV\"\"\"\n","        try:\n","            if not bids:\n","                print(\"No bids to save\")\n","                return\n","\n","            existing_bids = set()\n","            if os.path.exists(self.output_file):\n","                with open(self.output_file, 'r', encoding='utf-8') as f:\n","                    reader = csv.DictReader(f)\n","                    for row in reader:\n","                        existing_bids.add(f\"{row['RFP Number']}-{row['Title']}\")\n","\n","            new_bids = [bid for bid in bids if f\"{bid['RFP Number']}-{bid['Title']}\" not in existing_bids]\n","\n","            if new_bids:\n","                mode = 'w' if not os.path.exists(self.output_file) else 'a'\n","                with open(self.output_file, mode, newline='', encoding='utf-8') as f:\n","                    writer = csv.DictWriter(f, fieldnames=self.fieldnames)\n","                    if mode == 'w':\n","                        writer.writeheader()\n","                    writer.writerows(new_bids)\n","                print(f\"Added {len(new_bids)} new bids\")\n","            else:\n","                print(\"No new bids to add\")\n","\n","            # Download the CSV file\n","            files.download(self.output_file)\n","\n","        except Exception as e:\n","            print(f\"Error saving bids: {str(e)}\")\n","\n","    def run(self):\n","        \"\"\"Main execution method\"\"\"\n","        try:\n","            print(f\"Starting Westminster bids crawler at {datetime.now()}\")\n","            self.setup_csv()\n","            bids = self.get_bid_listings()\n","            self.save_bids(bids)\n","            print(\"Crawler execution completed\")\n","        finally:\n","            if hasattr(self, 'driver'):\n","                self.driver.quit()"]},{"cell_type":"code","source":["crawler = WestminsterBidsCrawler()\n","crawler.run()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":517},"id":"ilrY1MShTl2U","executionInfo":{"status":"ok","timestamp":1739217332421,"user_tz":480,"elapsed":24183,"user":{"displayName":"Ritunjay Murali","userId":"07921326813984298862"}},"outputId":"7f9beb2a-a837-466c-9583-b91c16cc51bf"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Attempting to use system chromedriver...\n","Chrome driver initialized successfully\n","Starting Westminster bids crawler at 2025-02-10 19:55:09.023492\n","CSV file already exists: westminster_bids.csv\n","\n","Attempt 1 to load page...\n","Page loaded successfully\n","Looking for bid table...\n","Found 4 rows in table\n","\n","Parsing new row...\n","Found 5 cells in row\n","Parsed bid: Workers' Compensation Claims Administration Services\n","\n","Parsing new row...\n","Found 5 cells in row\n","Parsed bid: CITYWIDE SLURRY SEAL IMPROVEMENTS\n","\n","Parsing new row...\n","Found 5 cells in row\n","Parsed bid: GROCERY GIFT CARD PURCHASE- REQUEST FOR PROPOSAL(RFP)\n","\n","Parsing new row...\n","Found 5 cells in row\n","Parsed bid: Basic Life Support (BLS) Ambulance Transport Services\n","Successfully parsed 4 bids\n","Added 4 new bids\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["download(\"download_df147a94-596b-49c0-a6d0-24c5add8446d\", \"westminster_bids.csv\", 819)"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Crawler execution completed\n"]}]},{"cell_type":"markdown","source":["## Disclaimer\n","This tool accesses publicly available information only from official government websites. It respects robots.txt guidelines and implements responsible scraping practices with delays between requests."],"metadata":{"id":"0JRrcS_QIqDY"}}]}