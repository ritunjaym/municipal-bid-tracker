{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOxtyas/5AsWz6wVHYtFJ24"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# City Bid Tracker - Orange\n","\n","Automated scraper for public procurement opportunities from Orange's official website.\n","\n","## Purpose\n","Helps contractors and vendors discover bidding opportunities by extracting:\n","- RFP numbers and titles\n","- Starting and closing dates\n","- Bid status information\n","- Direct links to full documentation\n","\n","## Setup & Usage\n","1. Run the dependency installation cell\n","2. Execute the crawler class definition\n","3. Run the final execution cell\n","4. CSV file will be automatically downloaded\n","\n","## Output\n","Creates `orange_bids.csv` with all current bid opportunities.\n","\n","## Technical Notes\n","This crawler includes status filter dropdown manipulation to ensure all bid types are captured, automatically selecting \"Open\" status for comprehensive results."],"metadata":{"id":"42PMy6EOKLmM"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"u4IpfJmoLE9o","executionInfo":{"status":"ok","timestamp":1740068696765,"user_tz":300,"elapsed":44040,"user":{"displayName":"Ritunjay Murali","userId":"07921326813984298862"}},"outputId":"4937b6ed-8576-4c49-fea8-3fe95bcff712"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting selenium\n","  Downloading selenium-4.29.0-py3-none-any.whl.metadata (7.1 kB)\n","Collecting webdriver_manager\n","  Downloading webdriver_manager-4.0.2-py2.py3-none-any.whl.metadata (12 kB)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n","Requirement already satisfied: urllib3<3,>=1.26 in /usr/local/lib/python3.11/dist-packages (from urllib3[socks]<3,>=1.26->selenium) (2.3.0)\n","Collecting trio~=0.17 (from selenium)\n","  Downloading trio-0.29.0-py3-none-any.whl.metadata (8.5 kB)\n","Collecting trio-websocket~=0.9 (from selenium)\n","  Downloading trio_websocket-0.12.1-py3-none-any.whl.metadata (5.1 kB)\n","Requirement already satisfied: certifi>=2021.10.8 in /usr/local/lib/python3.11/dist-packages (from selenium) (2025.1.31)\n","Requirement already satisfied: typing_extensions~=4.9 in /usr/local/lib/python3.11/dist-packages (from selenium) (4.12.2)\n","Requirement already satisfied: websocket-client~=1.8 in /usr/local/lib/python3.11/dist-packages (from selenium) (1.8.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from webdriver_manager) (2.32.3)\n","Collecting python-dotenv (from webdriver_manager)\n","  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from webdriver_manager) (24.2)\n","Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (1.26.4)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n","Requirement already satisfied: attrs>=23.2.0 in /usr/local/lib/python3.11/dist-packages (from trio~=0.17->selenium) (25.1.0)\n","Collecting sortedcontainers (from trio~=0.17->selenium)\n","  Downloading sortedcontainers-2.4.0-py2.py3-none-any.whl.metadata (10 kB)\n","Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from trio~=0.17->selenium) (3.10)\n","Collecting outcome (from trio~=0.17->selenium)\n","  Downloading outcome-1.3.0.post0-py2.py3-none-any.whl.metadata (2.6 kB)\n","Requirement already satisfied: sniffio>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from trio~=0.17->selenium) (1.3.1)\n","Collecting wsproto>=0.14 (from trio-websocket~=0.9->selenium)\n","  Downloading wsproto-1.2.0-py3-none-any.whl.metadata (5.6 kB)\n","Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in /usr/local/lib/python3.11/dist-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->webdriver_manager) (3.4.1)\n","Requirement already satisfied: h11<1,>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n","Downloading selenium-4.29.0-py3-none-any.whl (9.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.5/9.5 MB\u001b[0m \u001b[31m45.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading webdriver_manager-4.0.2-py2.py3-none-any.whl (27 kB)\n","Downloading trio-0.29.0-py3-none-any.whl (492 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m492.9/492.9 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading trio_websocket-0.12.1-py3-none-any.whl (21 kB)\n","Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n","Downloading outcome-1.3.0.post0-py2.py3-none-any.whl (10 kB)\n","Downloading wsproto-1.2.0-py3-none-any.whl (24 kB)\n","Downloading sortedcontainers-2.4.0-py2.py3-none-any.whl (29 kB)\n","Installing collected packages: sortedcontainers, wsproto, python-dotenv, outcome, webdriver_manager, trio, trio-websocket, selenium\n","Successfully installed outcome-1.3.0.post0 python-dotenv-1.0.1 selenium-4.29.0 sortedcontainers-2.4.0 trio-0.29.0 trio-websocket-0.12.1 webdriver_manager-4.0.2 wsproto-1.2.0\n","Get:1 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n","Get:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n","Hit:3 http://archive.ubuntu.com/ubuntu jammy InRelease\n","Get:4 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,632 B]\n","Get:5 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n","Get:6 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\n","Get:7 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n","Get:8 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [1,317 kB]\n","Hit:9 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n","Hit:10 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n","Hit:11 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n","Get:12 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,230 kB]\n","Get:13 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [2,610 kB]\n","Get:14 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,661 kB]\n","Get:15 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [8,692 kB]\n","Get:16 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [3,793 kB]\n","Get:17 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [2,939 kB]\n","Get:18 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,526 kB]\n","Fetched 25.2 MB in 5s (4,866 kB/s)\n","Reading package lists... Done\n","W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n","Reading package lists... Done\n","Building dependency tree... Done\n","Reading state information... Done\n","The following additional packages will be installed:\n","  apparmor chromium-browser libfuse3-3 liblzo2-2 snapd squashfs-tools systemd-hwe-hwdb udev\n","Suggested packages:\n","  apparmor-profiles-extra apparmor-utils fuse3 zenity | kdialog\n","The following NEW packages will be installed:\n","  apparmor chromium-browser chromium-chromedriver libfuse3-3 liblzo2-2 snapd squashfs-tools\n","  systemd-hwe-hwdb udev\n","0 upgraded, 9 newly installed, 0 to remove and 30 not upgraded.\n","Need to get 30.1 MB of archives.\n","After this operation, 123 MB of additional disk space will be used.\n","Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 apparmor amd64 3.0.4-2ubuntu2.4 [598 kB]\n","Get:2 http://archive.ubuntu.com/ubuntu jammy/main amd64 liblzo2-2 amd64 2.10-2build3 [53.7 kB]\n","Get:3 http://archive.ubuntu.com/ubuntu jammy/main amd64 squashfs-tools amd64 1:4.5-3build1 [159 kB]\n","Get:4 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 udev amd64 249.11-0ubuntu3.12 [1,557 kB]\n","Get:5 http://archive.ubuntu.com/ubuntu jammy/main amd64 libfuse3-3 amd64 3.10.5-1build1 [81.2 kB]\n","Get:6 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 snapd amd64 2.66.1+22.04 [27.6 MB]\n","Get:7 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 chromium-browser amd64 1:85.0.4183.83-0ubuntu2.22.04.1 [49.2 kB]\n","Get:8 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 chromium-chromedriver amd64 1:85.0.4183.83-0ubuntu2.22.04.1 [2,308 B]\n","Get:9 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 systemd-hwe-hwdb all 249.11.5 [3,228 B]\n","Fetched 30.1 MB in 1s (33.6 MB/s)\n","Preconfiguring packages ...\n","Selecting previously unselected package apparmor.\n","(Reading database ... 124926 files and directories currently installed.)\n","Preparing to unpack .../0-apparmor_3.0.4-2ubuntu2.4_amd64.deb ...\n","Unpacking apparmor (3.0.4-2ubuntu2.4) ...\n","Selecting previously unselected package liblzo2-2:amd64.\n","Preparing to unpack .../1-liblzo2-2_2.10-2build3_amd64.deb ...\n","Unpacking liblzo2-2:amd64 (2.10-2build3) ...\n","Selecting previously unselected package squashfs-tools.\n","Preparing to unpack .../2-squashfs-tools_1%3a4.5-3build1_amd64.deb ...\n","Unpacking squashfs-tools (1:4.5-3build1) ...\n","Selecting previously unselected package udev.\n","Preparing to unpack .../3-udev_249.11-0ubuntu3.12_amd64.deb ...\n","Unpacking udev (249.11-0ubuntu3.12) ...\n","Selecting previously unselected package libfuse3-3:amd64.\n","Preparing to unpack .../4-libfuse3-3_3.10.5-1build1_amd64.deb ...\n","Unpacking libfuse3-3:amd64 (3.10.5-1build1) ...\n","Selecting previously unselected package snapd.\n","Preparing to unpack .../5-snapd_2.66.1+22.04_amd64.deb ...\n","Unpacking snapd (2.66.1+22.04) ...\n","Setting up apparmor (3.0.4-2ubuntu2.4) ...\n","Created symlink /etc/systemd/system/sysinit.target.wants/apparmor.service → /lib/systemd/system/apparmor.service.\n","Setting up liblzo2-2:amd64 (2.10-2build3) ...\n","Setting up squashfs-tools (1:4.5-3build1) ...\n","Setting up udev (249.11-0ubuntu3.12) ...\n","invoke-rc.d: could not determine current runlevel\n","invoke-rc.d: policy-rc.d denied execution of start.\n","Setting up libfuse3-3:amd64 (3.10.5-1build1) ...\n","Setting up snapd (2.66.1+22.04) ...\n","Created symlink /etc/systemd/system/multi-user.target.wants/snapd.apparmor.service → /lib/systemd/system/snapd.apparmor.service.\n","Created symlink /etc/systemd/system/multi-user.target.wants/snapd.autoimport.service → /lib/systemd/system/snapd.autoimport.service.\n","Created symlink /etc/systemd/system/multi-user.target.wants/snapd.core-fixup.service → /lib/systemd/system/snapd.core-fixup.service.\n","Created symlink /etc/systemd/system/multi-user.target.wants/snapd.recovery-chooser-trigger.service → /lib/systemd/system/snapd.recovery-chooser-trigger.service.\n","Created symlink /etc/systemd/system/multi-user.target.wants/snapd.seeded.service → /lib/systemd/system/snapd.seeded.service.\n","Created symlink /etc/systemd/system/cloud-final.service.wants/snapd.seeded.service → /lib/systemd/system/snapd.seeded.service.\n","Unit /lib/systemd/system/snapd.seeded.service is added as a dependency to a non-existent unit cloud-final.service.\n","Created symlink /etc/systemd/system/multi-user.target.wants/snapd.service → /lib/systemd/system/snapd.service.\n","Created symlink /etc/systemd/system/timers.target.wants/snapd.snap-repair.timer → /lib/systemd/system/snapd.snap-repair.timer.\n","Created symlink /etc/systemd/system/sockets.target.wants/snapd.socket → /lib/systemd/system/snapd.socket.\n","Created symlink /etc/systemd/system/final.target.wants/snapd.system-shutdown.service → /lib/systemd/system/snapd.system-shutdown.service.\n","Selecting previously unselected package chromium-browser.\n","(Reading database ... 125363 files and directories currently installed.)\n","Preparing to unpack .../chromium-browser_1%3a85.0.4183.83-0ubuntu2.22.04.1_amd64.deb ...\n","=> Installing the chromium snap\n","==> Checking connectivity with the snap store\n","===> System doesn't have a working snapd, skipping\n","Unpacking chromium-browser (1:85.0.4183.83-0ubuntu2.22.04.1) ...\n","Selecting previously unselected package chromium-chromedriver.\n","Preparing to unpack .../chromium-chromedriver_1%3a85.0.4183.83-0ubuntu2.22.04.1_amd64.deb ...\n","Unpacking chromium-chromedriver (1:85.0.4183.83-0ubuntu2.22.04.1) ...\n","Selecting previously unselected package systemd-hwe-hwdb.\n","Preparing to unpack .../systemd-hwe-hwdb_249.11.5_all.deb ...\n","Unpacking systemd-hwe-hwdb (249.11.5) ...\n","Setting up systemd-hwe-hwdb (249.11.5) ...\n","Setting up chromium-browser (1:85.0.4183.83-0ubuntu2.22.04.1) ...\n","update-alternatives: using /usr/bin/chromium-browser to provide /usr/bin/x-www-browser (x-www-browser) in auto mode\n","update-alternatives: using /usr/bin/chromium-browser to provide /usr/bin/gnome-www-browser (gnome-www-browser) in auto mode\n","Setting up chromium-chromedriver (1:85.0.4183.83-0ubuntu2.22.04.1) ...\n","Processing triggers for udev (249.11-0ubuntu3.12) ...\n","Processing triggers for mailcap (3.70+nmu1ubuntu1) ...\n","Processing triggers for hicolor-icon-theme (0.17-2) ...\n","Processing triggers for libc-bin (2.35-0ubuntu3.8) ...\n","/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libumf.so.0 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n","\n","Processing triggers for man-db (2.10.2-1) ...\n","Processing triggers for dbus (1.12.20-2ubuntu4.1) ...\n"]}],"source":["!pip install selenium webdriver_manager pandas\n","\n","# Install Chrome and ChromeDriver\n","!apt-get update\n","!apt install chromium-chromedriver"]},{"cell_type":"code","source":["from selenium import webdriver\n","from selenium.webdriver.common.by import By\n","from selenium.webdriver.support.ui import WebDriverWait\n","from selenium.webdriver.support import expected_conditions as EC\n","from selenium.webdriver.chrome.service import Service\n","from selenium.webdriver.chrome.options import Options\n","from webdriver_manager.chrome import ChromeDriverManager\n","from datetime import datetime\n","import csv\n","import os\n","import time\n","from google.colab import files\n","import random\n","\n","class OrangeBidsCrawler:\n","    def __init__(self):\n","        self.base_url = \"https://www.cityoforange.org/business/current-bids-proposals\"\n","        self.output_file = \"orange_bids.csv\"\n","        self.fieldnames = [\n","            \"RFP Number\",\n","            \"Title\",\n","            \"Starting Date\",\n","            \"Closing Date\",\n","            \"Status\",\n","            \"Details URL\",\n","            \"Last Updated\"\n","        ]\n","        self.max_retries = 3\n","        self.setup_driver()\n","\n","    def setup_driver(self):\n","        \"\"\"Setup Chrome driver with enhanced options\"\"\"\n","        chrome_options = Options()\n","        chrome_options.add_argument('--headless')\n","        chrome_options.add_argument('--no-sandbox')\n","        chrome_options.add_argument('--disable-dev-shm-usage')\n","        chrome_options.add_argument('--disable-gpu')\n","        chrome_options.add_argument('--window-size=1920,1080')\n","\n","        # Add realistic browser headers\n","        chrome_options.add_argument('--user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36')\n","        chrome_options.add_argument('--accept-language=en-US,en;q=0.9')\n","        chrome_options.add_argument('--disable-blink-features=AutomationControlled')\n","\n","        try:\n","            print(\"Attempting to use system chromedriver...\")\n","            self.driver = webdriver.Chrome(options=chrome_options)\n","        except Exception as e:\n","            print(f\"System chromedriver failed: {str(e)}\")\n","            print(\"Attempting to use ChromeDriverManager...\")\n","            service = Service(ChromeDriverManager().install())\n","            self.driver = webdriver.Chrome(service=service, options=chrome_options)\n","\n","        self.driver.set_page_load_timeout(30)\n","        self.wait = WebDriverWait(self.driver, 15)\n","        print(\"Chrome driver initialized successfully\")\n","\n","    def random_delay(self):\n","        \"\"\"Add random delay between actions\"\"\"\n","        time.sleep(random.uniform(2, 5))\n","\n","    def parse_bid_item(self, row):\n","        \"\"\"Parse individual bid listing row\"\"\"\n","        try:\n","            print(\"\\nParsing new row...\")\n","            bid_data = {\n","                \"RFP Number\": \"\",\n","                \"Title\": \"\",\n","                \"Starting Date\": \"\",\n","                \"Closing Date\": \"\",\n","                \"Status\": \"\",\n","                \"Details URL\": \"\",\n","                \"Last Updated\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n","            }\n","\n","            # Get all cells\n","            cells = row.find_elements(By.TAG_NAME, \"td\")\n","            if len(cells) >= 5:\n","                # RFP Number\n","                bid_data[\"RFP Number\"] = cells[0].text.strip()\n","\n","                # Title and URL\n","                try:\n","                    title_link = cells[1].find_element(By.TAG_NAME, \"a\")\n","                    bid_data[\"Title\"] = title_link.text.strip()\n","                    bid_data[\"Details URL\"] = title_link.get_attribute(\"href\")\n","                except Exception as e:\n","                    print(f\"Error extracting title/URL: {str(e)}\")\n","\n","                # Dates and Status\n","                bid_data[\"Starting Date\"] = cells[2].text.strip()\n","                bid_data[\"Closing Date\"] = cells[3].text.strip()\n","                bid_data[\"Status\"] = cells[4].text.strip()\n","\n","                print(f\"Parsed bid: {bid_data['Title']}\")\n","                return bid_data if bid_data[\"Title\"] else None\n","\n","            return None\n","\n","        except Exception as e:\n","            print(f\"Error parsing bid item: {str(e)}\")\n","            return None\n","\n","    def setup_csv(self):\n","        \"\"\"Create or verify CSV file with headers\"\"\"\n","        try:\n","            if not os.path.exists(self.output_file):\n","                with open(self.output_file, 'w', newline='', encoding='utf-8') as f:\n","                    writer = csv.DictWriter(f, fieldnames=self.fieldnames)\n","                    writer.writeheader()\n","                print(f\"Created new CSV file: {self.output_file}\")\n","            else:\n","                print(f\"CSV file already exists: {self.output_file}\")\n","        except Exception as e:\n","            print(f\"Error setting up CSV: {str(e)}\")\n","\n","    def get_page_with_retry(self):\n","        \"\"\"Attempt to load the page with retries\"\"\"\n","        for attempt in range(self.max_retries):\n","            try:\n","                print(f\"\\nAttempt {attempt + 1} to load page...\")\n","                self.driver.get(self.base_url)\n","                self.random_delay()\n","\n","                # Check for access denied\n","                if \"Access Denied\" in self.driver.page_source:\n","                    print(\"Access Denied detected, retrying...\")\n","                    continue\n","\n","                print(\"Page loaded successfully\")\n","                return True\n","            except Exception as e:\n","                print(f\"Error loading page: {str(e)}\")\n","                if attempt < self.max_retries - 1:\n","                    wait_time = (attempt + 1) * 5\n","                    print(f\"Waiting {wait_time} seconds before retry...\")\n","                    time.sleep(wait_time)\n","                continue\n","        return False\n","\n","    def get_bid_listings(self):\n","        \"\"\"Fetch and parse all bid listings\"\"\"\n","        try:\n","            if not self.get_page_with_retry():\n","                print(\"Failed to load page after all retries\")\n","                return []\n","\n","            # Find and process status filter dropdown\n","            try:\n","                status_dropdown = self.wait.until(\n","                    EC.presence_of_element_located((By.ID, \"rfpStas_5683_7176_393\"))\n","                )\n","                # Select \"Open\" status if not already selected\n","                if status_dropdown.get_attribute(\"value\") != \"4\":\n","                    status_dropdown.find_element(By.CSS_SELECTOR, \"option[value='4']\").click()\n","                    self.random_delay()\n","            except Exception as e:\n","                print(f\"Error with status filter: {str(e)}\")\n","\n","            print(\"Looking for bid table...\")\n","            table = None\n","\n","            try:\n","                table = self.wait.until(\n","                    EC.presence_of_element_located((By.CSS_SELECTOR, \"table.listtable\"))\n","                )\n","            except Exception as e:\n","                print(f\"Error finding table: {str(e)}\")\n","                return []\n","\n","            # Find all bid rows\n","            rows = table.find_elements(By.CSS_SELECTOR, \"tbody tr\")\n","            print(f\"Found {len(rows)} rows in table\")\n","\n","            bids = []\n","            for row in rows:\n","                bid_data = self.parse_bid_item(row)\n","                if bid_data:\n","                    bids.append(bid_data)\n","                self.random_delay()\n","\n","            print(f\"Successfully parsed {len(bids)} bids\")\n","            return bids\n","\n","        except Exception as e:\n","            print(f\"Error fetching bid listings: {str(e)}\")\n","            return []\n","\n","    def save_bids(self, bids):\n","        \"\"\"Save bid data to CSV\"\"\"\n","        try:\n","            if not bids:\n","                print(\"No bids to save\")\n","                return\n","\n","            existing_bids = set()\n","            if os.path.exists(self.output_file):\n","                with open(self.output_file, 'r', encoding='utf-8') as f:\n","                    reader = csv.DictReader(f)\n","                    for row in reader:\n","                        existing_bids.add(f\"{row['RFP Number']}-{row['Title']}\")\n","\n","            new_bids = [\n","                bid for bid in bids\n","                if f\"{bid['RFP Number']}-{bid['Title']}\" not in existing_bids\n","            ]\n","\n","            if new_bids:\n","                mode = 'w' if not os.path.exists(self.output_file) else 'a'\n","                with open(self.output_file, mode, newline='', encoding='utf-8') as f:\n","                    writer = csv.DictWriter(f, fieldnames=self.fieldnames)\n","                    if mode == 'w':\n","                        writer.writeheader()\n","                    writer.writerows(new_bids)\n","                print(f\"Added {len(new_bids)} new bids\")\n","            else:\n","                print(\"No new bids to add\")\n","\n","            # Download the CSV file\n","            files.download(self.output_file)\n","\n","        except Exception as e:\n","            print(f\"Error saving bids: {str(e)}\")\n","\n","    def run(self):\n","        \"\"\"Main execution method\"\"\"\n","        try:\n","            print(f\"Starting Orange bids crawler at {datetime.now()}\")\n","            self.setup_csv()\n","            bids = self.get_bid_listings()\n","            self.save_bids(bids)\n","            print(\"Crawler execution completed\")\n","        finally:\n","            if hasattr(self, 'driver'):\n","                self.driver.quit()"],"metadata":{"id":"M5mvAR0DLUtW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["crawler = OrangeBidsCrawler()\n","crawler.run()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":446},"id":"Es2Fr5NvLU2L","executionInfo":{"status":"ok","timestamp":1740068817722,"user_tz":300,"elapsed":40209,"user":{"displayName":"Ritunjay Murali","userId":"07921326813984298862"}},"outputId":"0992e859-6033-499e-bee9-77c51582fc54"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Attempting to use system chromedriver...\n","Chrome driver initialized successfully\n","Starting Orange bids crawler at 2025-02-20 16:26:28.955350\n","Created new CSV file: orange_bids.csv\n","\n","Attempt 1 to load page...\n","Page loaded successfully\n","Looking for bid table...\n","Found 4 rows in table\n","\n","Parsing new row...\n","Parsed bid: RF BID - 24-25.14 - CDBG FY 2024 - 2025 Pixley Neighborhood Street Rehabilitation\n","\n","Parsing new row...\n","Parsed bid: RF BID - 24-25.15 - CDBG FY 2024 - 2025 ADA Wheelchair Access Ramp Replacement\n","\n","Parsing new row...\n","Parsed bid: RF BID - 24-25.13 - Well 29 Drilling\n","\n","Parsing new row...\n","Parsed bid: RF BID - 24-25.16 - Tot Lot Wood Fiber Replenish Program\n","Successfully parsed 4 bids\n","Added 4 new bids\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["download(\"download_061b155e-44d0-41f4-a2a8-0e0034f9790c\", \"orange_bids.csv\", 908)"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Crawler execution completed\n"]}]},{"cell_type":"markdown","source":["## Disclaimer\n","This tool accesses publicly available information only from official government websites. It respects robots.txt guidelines and implements responsible scraping practices with delays between requests."],"metadata":{"id":"-Ky2dm9vKQP1"}}]}