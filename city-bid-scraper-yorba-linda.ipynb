{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNW8DBLDgNyv/Xbhmsg7O57"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# City Bid Tracker - Yorba Linda\n","\n","Automated scraper for public procurement opportunities from Yorba Linda's official website.\n","\n","## Purpose\n","Helps contractors and vendors discover bidding opportunities by extracting:\n","- Bid titles and descriptions\n","- Category classifications\n","- Status and closing dates\n","- Direct links to full documentation\n","\n","## Setup & Usage\n","1. Run the dependency installation cell\n","2. Execute the crawler class definition\n","3. Run the final execution cell\n","4. CSV file will be automatically downloaded\n","\n","## Output\n","Creates `yorba_linda_bids.csv` with all current and historical bid opportunities."],"metadata":{"id":"THLlCSr_IOlU"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"O2mtPr6TZ_jO","executionInfo":{"status":"ok","timestamp":1739162578384,"user_tz":480,"elapsed":30396,"user":{"displayName":"Ritunjay Murali","userId":"07921326813984298862"}},"outputId":"62fef81e-c9a4-431b-fc9f-587faf75e609"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["!pip install selenium webdriver_manager pandas\n","\n","# Install Chrome and ChromeDriver\n","!apt-get update\n","!apt install chromium-chromedriver\n","\n","import os\n","import time\n","from datetime import datetime\n","import csv\n","from selenium import webdriver\n","from selenium.webdriver.common.by import By\n","from selenium.webdriver.support.ui import WebDriverWait\n","from selenium.webdriver.support import expected_conditions as EC\n","from selenium.webdriver.chrome.service import Service\n","from selenium.webdriver.chrome.options import Options\n","from webdriver_manager.chrome import ChromeDriverManager\n","from google.colab import files"],"metadata":{"id":"njXmpvEvK-Cd","executionInfo":{"status":"ok","timestamp":1739162623977,"user_tz":480,"elapsed":45595,"user":{"displayName":"Ritunjay Murali","userId":"07921326813984298862"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"1fa4116e-a3a4-4721-c0dd-d0c9dd6a7652"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting selenium\n","  Downloading selenium-4.28.1-py3-none-any.whl.metadata (7.1 kB)\n","Collecting webdriver_manager\n","  Downloading webdriver_manager-4.0.2-py2.py3-none-any.whl.metadata (12 kB)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n","Requirement already satisfied: urllib3<3,>=1.26 in /usr/local/lib/python3.11/dist-packages (from urllib3[socks]<3,>=1.26->selenium) (2.3.0)\n","Collecting trio~=0.17 (from selenium)\n","  Downloading trio-0.28.0-py3-none-any.whl.metadata (8.5 kB)\n","Collecting trio-websocket~=0.9 (from selenium)\n","  Downloading trio_websocket-0.11.1-py3-none-any.whl.metadata (4.7 kB)\n","Requirement already satisfied: certifi>=2021.10.8 in /usr/local/lib/python3.11/dist-packages (from selenium) (2025.1.31)\n","Requirement already satisfied: typing_extensions~=4.9 in /usr/local/lib/python3.11/dist-packages (from selenium) (4.12.2)\n","Requirement already satisfied: websocket-client~=1.8 in /usr/local/lib/python3.11/dist-packages (from selenium) (1.8.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from webdriver_manager) (2.32.3)\n","Collecting python-dotenv (from webdriver_manager)\n","  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from webdriver_manager) (24.2)\n","Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (1.26.4)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n","Requirement already satisfied: attrs>=23.2.0 in /usr/local/lib/python3.11/dist-packages (from trio~=0.17->selenium) (25.1.0)\n","Collecting sortedcontainers (from trio~=0.17->selenium)\n","  Downloading sortedcontainers-2.4.0-py2.py3-none-any.whl.metadata (10 kB)\n","Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from trio~=0.17->selenium) (3.10)\n","Collecting outcome (from trio~=0.17->selenium)\n","  Downloading outcome-1.3.0.post0-py2.py3-none-any.whl.metadata (2.6 kB)\n","Requirement already satisfied: sniffio>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from trio~=0.17->selenium) (1.3.1)\n","Collecting wsproto>=0.14 (from trio-websocket~=0.9->selenium)\n","  Downloading wsproto-1.2.0-py3-none-any.whl.metadata (5.6 kB)\n","Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in /usr/local/lib/python3.11/dist-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->webdriver_manager) (3.4.1)\n","Requirement already satisfied: h11<1,>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n","Downloading selenium-4.28.1-py3-none-any.whl (9.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.5/9.5 MB\u001b[0m \u001b[31m31.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading webdriver_manager-4.0.2-py2.py3-none-any.whl (27 kB)\n","Downloading trio-0.28.0-py3-none-any.whl (486 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m486.3/486.3 kB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading trio_websocket-0.11.1-py3-none-any.whl (17 kB)\n","Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n","Downloading wsproto-1.2.0-py3-none-any.whl (24 kB)\n","Downloading outcome-1.3.0.post0-py2.py3-none-any.whl (10 kB)\n","Downloading sortedcontainers-2.4.0-py2.py3-none-any.whl (29 kB)\n","Installing collected packages: sortedcontainers, wsproto, python-dotenv, outcome, webdriver_manager, trio, trio-websocket, selenium\n","Successfully installed outcome-1.3.0.post0 python-dotenv-1.0.1 selenium-4.28.1 sortedcontainers-2.4.0 trio-0.28.0 trio-websocket-0.11.1 webdriver_manager-4.0.2 wsproto-1.2.0\n","Hit:1 http://archive.ubuntu.com/ubuntu jammy InRelease\n","Get:2 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n","Get:3 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n","Get:4 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n","Get:5 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,632 B]\n","Get:6 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\n","Get:7 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n","Hit:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n","Get:9 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [1,309 kB]\n","Get:10 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease [24.3 kB]\n","Hit:11 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n","Get:12 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ Packages [66.7 kB]\n","Get:13 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,523 kB]\n","Get:14 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [2,907 kB]\n","Get:15 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [8,665 kB]\n","Get:16 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,653 kB]\n","Get:17 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [2,606 kB]\n","Get:18 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,230 kB]\n","Get:19 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy/main amd64 Packages [57.8 kB]\n","Fetched 21.4 MB in 4s (4,802 kB/s)\n","Reading package lists... Done\n","W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n","Reading package lists... Done\n","Building dependency tree... Done\n","Reading state information... Done\n","The following additional packages will be installed:\n","  apparmor chromium-browser libfuse3-3 liblzo2-2 snapd squashfs-tools systemd-hwe-hwdb udev\n","Suggested packages:\n","  apparmor-profiles-extra apparmor-utils fuse3 zenity | kdialog\n","The following NEW packages will be installed:\n","  apparmor chromium-browser chromium-chromedriver libfuse3-3 liblzo2-2 snapd squashfs-tools\n","  systemd-hwe-hwdb udev\n","0 upgraded, 9 newly installed, 0 to remove and 25 not upgraded.\n","Need to get 30.1 MB of archives.\n","After this operation, 123 MB of additional disk space will be used.\n","Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 apparmor amd64 3.0.4-2ubuntu2.4 [598 kB]\n","Get:2 http://archive.ubuntu.com/ubuntu jammy/main amd64 liblzo2-2 amd64 2.10-2build3 [53.7 kB]\n","Get:3 http://archive.ubuntu.com/ubuntu jammy/main amd64 squashfs-tools amd64 1:4.5-3build1 [159 kB]\n","Get:4 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 udev amd64 249.11-0ubuntu3.12 [1,557 kB]\n","Get:5 http://archive.ubuntu.com/ubuntu jammy/main amd64 libfuse3-3 amd64 3.10.5-1build1 [81.2 kB]\n","Get:6 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 snapd amd64 2.66.1+22.04 [27.6 MB]\n","Get:7 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 chromium-browser amd64 1:85.0.4183.83-0ubuntu2.22.04.1 [49.2 kB]\n","Get:8 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 chromium-chromedriver amd64 1:85.0.4183.83-0ubuntu2.22.04.1 [2,308 B]\n","Get:9 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 systemd-hwe-hwdb all 249.11.5 [3,228 B]\n","Fetched 30.1 MB in 1s (38.8 MB/s)\n","Preconfiguring packages ...\n","Selecting previously unselected package apparmor.\n","(Reading database ... 124926 files and directories currently installed.)\n","Preparing to unpack .../0-apparmor_3.0.4-2ubuntu2.4_amd64.deb ...\n","Unpacking apparmor (3.0.4-2ubuntu2.4) ...\n","Selecting previously unselected package liblzo2-2:amd64.\n","Preparing to unpack .../1-liblzo2-2_2.10-2build3_amd64.deb ...\n","Unpacking liblzo2-2:amd64 (2.10-2build3) ...\n","Selecting previously unselected package squashfs-tools.\n","Preparing to unpack .../2-squashfs-tools_1%3a4.5-3build1_amd64.deb ...\n","Unpacking squashfs-tools (1:4.5-3build1) ...\n","Selecting previously unselected package udev.\n","Preparing to unpack .../3-udev_249.11-0ubuntu3.12_amd64.deb ...\n","Unpacking udev (249.11-0ubuntu3.12) ...\n","Selecting previously unselected package libfuse3-3:amd64.\n","Preparing to unpack .../4-libfuse3-3_3.10.5-1build1_amd64.deb ...\n","Unpacking libfuse3-3:amd64 (3.10.5-1build1) ...\n","Selecting previously unselected package snapd.\n","Preparing to unpack .../5-snapd_2.66.1+22.04_amd64.deb ...\n","Unpacking snapd (2.66.1+22.04) ...\n","Setting up apparmor (3.0.4-2ubuntu2.4) ...\n","Created symlink /etc/systemd/system/sysinit.target.wants/apparmor.service → /lib/systemd/system/apparmor.service.\n","Setting up liblzo2-2:amd64 (2.10-2build3) ...\n","Setting up squashfs-tools (1:4.5-3build1) ...\n","Setting up udev (249.11-0ubuntu3.12) ...\n","invoke-rc.d: could not determine current runlevel\n","invoke-rc.d: policy-rc.d denied execution of start.\n","Setting up libfuse3-3:amd64 (3.10.5-1build1) ...\n","Setting up snapd (2.66.1+22.04) ...\n","Created symlink /etc/systemd/system/multi-user.target.wants/snapd.apparmor.service → /lib/systemd/system/snapd.apparmor.service.\n","Created symlink /etc/systemd/system/multi-user.target.wants/snapd.autoimport.service → /lib/systemd/system/snapd.autoimport.service.\n","Created symlink /etc/systemd/system/multi-user.target.wants/snapd.core-fixup.service → /lib/systemd/system/snapd.core-fixup.service.\n","Created symlink /etc/systemd/system/multi-user.target.wants/snapd.recovery-chooser-trigger.service → /lib/systemd/system/snapd.recovery-chooser-trigger.service.\n","Created symlink /etc/systemd/system/multi-user.target.wants/snapd.seeded.service → /lib/systemd/system/snapd.seeded.service.\n","Created symlink /etc/systemd/system/cloud-final.service.wants/snapd.seeded.service → /lib/systemd/system/snapd.seeded.service.\n","Unit /lib/systemd/system/snapd.seeded.service is added as a dependency to a non-existent unit cloud-final.service.\n","Created symlink /etc/systemd/system/multi-user.target.wants/snapd.service → /lib/systemd/system/snapd.service.\n","Created symlink /etc/systemd/system/timers.target.wants/snapd.snap-repair.timer → /lib/systemd/system/snapd.snap-repair.timer.\n","Created symlink /etc/systemd/system/sockets.target.wants/snapd.socket → /lib/systemd/system/snapd.socket.\n","Created symlink /etc/systemd/system/final.target.wants/snapd.system-shutdown.service → /lib/systemd/system/snapd.system-shutdown.service.\n","Selecting previously unselected package chromium-browser.\n","(Reading database ... 125363 files and directories currently installed.)\n","Preparing to unpack .../chromium-browser_1%3a85.0.4183.83-0ubuntu2.22.04.1_amd64.deb ...\n","=> Installing the chromium snap\n","==> Checking connectivity with the snap store\n","===> System doesn't have a working snapd, skipping\n","Unpacking chromium-browser (1:85.0.4183.83-0ubuntu2.22.04.1) ...\n","Selecting previously unselected package chromium-chromedriver.\n","Preparing to unpack .../chromium-chromedriver_1%3a85.0.4183.83-0ubuntu2.22.04.1_amd64.deb ...\n","Unpacking chromium-chromedriver (1:85.0.4183.83-0ubuntu2.22.04.1) ...\n","Selecting previously unselected package systemd-hwe-hwdb.\n","Preparing to unpack .../systemd-hwe-hwdb_249.11.5_all.deb ...\n","Unpacking systemd-hwe-hwdb (249.11.5) ...\n","Setting up systemd-hwe-hwdb (249.11.5) ...\n","Setting up chromium-browser (1:85.0.4183.83-0ubuntu2.22.04.1) ...\n","update-alternatives: using /usr/bin/chromium-browser to provide /usr/bin/x-www-browser (x-www-browser) in auto mode\n","update-alternatives: using /usr/bin/chromium-browser to provide /usr/bin/gnome-www-browser (gnome-www-browser) in auto mode\n","Setting up chromium-chromedriver (1:85.0.4183.83-0ubuntu2.22.04.1) ...\n","Processing triggers for udev (249.11-0ubuntu3.12) ...\n","Processing triggers for mailcap (3.70+nmu1ubuntu1) ...\n","Processing triggers for hicolor-icon-theme (0.17-2) ...\n","Processing triggers for libc-bin (2.35-0ubuntu3.8) ...\n","/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libumf.so.0 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n","\n","Processing triggers for man-db (2.10.2-1) ...\n","Processing triggers for dbus (1.12.20-2ubuntu4.1) ...\n"]}]},{"cell_type":"code","source":["class YorbaLindaBidsCrawler:\n","    def __init__(self):\n","        self.base_url = \"https://www.yorbalindaca.gov/bids.aspx\"\n","        self.output_file = \"yorba_linda_bids.csv\"\n","        self.fieldnames = [\n","            \"Category\",\n","            \"Bid Title\",\n","            \"Description\",\n","            \"Status\",\n","            \"Closes\",\n","            \"Bid Details URL\",\n","            \"Last Updated\"\n","        ]\n","        self.setup_driver()\n","\n","    def setup_driver(self):\n","        \"\"\"Setup Chrome driver with Colab-specific options\"\"\"\n","        chrome_options = Options()\n","        chrome_options.add_argument('--headless')\n","        chrome_options.add_argument('--no-sandbox')\n","        chrome_options.add_argument('--disable-dev-shm-usage')\n","        chrome_options.add_argument(\"--disable-gpu\")\n","        chrome_options.add_argument(\"--window-size=1920,1080\")\n","\n","        try:\n","            print(\"Attempting to use system chromedriver...\")\n","            self.driver = webdriver.Chrome(options=chrome_options)\n","        except Exception as e:\n","            print(f\"System chromedriver failed: {str(e)}\")\n","            print(\"Attempting to use ChromeDriverManager...\")\n","            service = Service(ChromeDriverManager().install())\n","            self.driver = webdriver.Chrome(service=service, options=chrome_options)\n","\n","        self.wait = WebDriverWait(self.driver, 10)\n","        print(\"Chrome driver initialized successfully\")\n","\n","    def parse_bid_item(self, bid_item, category):\n","        \"\"\"Parse individual bid listing\"\"\"\n","        try:\n","            bid_data = {\n","                \"Category\": category,\n","                \"Bid Title\": \"\",\n","                \"Description\": \"\",\n","                \"Status\": \"\",\n","                \"Closes\": \"\",\n","                \"Bid Details URL\": \"\",\n","                \"Last Updated\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n","            }\n","\n","            # Get bid title and URL\n","            try:\n","                title_elem = bid_item.find_element(By.CSS_SELECTOR, \".bidTitle a\")\n","                bid_data[\"Bid Title\"] = title_elem.text.strip()\n","                bid_data[\"Bid Details URL\"] = title_elem.get_attribute(\"href\")\n","\n","                # Get description (text after title)\n","                desc_elem = bid_item.find_element(By.CSS_SELECTOR, \".bidTitle span:nth-child(3)\")\n","                desc_text = desc_elem.text.strip()\n","                # Remove the \"[Read on]\" text if present\n","                desc_text = desc_text.split(\"[Read\")[0].strip()\n","                bid_data[\"Description\"] = desc_text\n","\n","            except Exception as e:\n","                print(f\"Error parsing title/description: {str(e)}\")\n","                return None\n","\n","            # Get bid status info\n","            try:\n","                status_section = bid_item.find_element(By.CLASS_NAME, \"bidStatus\")\n","                status_divs = status_section.find_elements(By.TAG_NAME, \"div\")\n","\n","                if len(status_divs) >= 2:\n","                    spans_values = status_divs[1].find_elements(By.TAG_NAME, \"span\")\n","                    if len(spans_values) >= 2:\n","                        bid_data[\"Status\"] = spans_values[0].text.strip()\n","                        bid_data[\"Closes\"] = spans_values[1].text.strip()\n","\n","            except Exception as e:\n","                print(f\"Error parsing status: {str(e)}\")\n","\n","            return bid_data\n","\n","        except Exception as e:\n","            print(f\"Error parsing bid item: {str(e)}\")\n","            return None\n","\n","    def setup_csv(self):\n","        \"\"\"Create or verify CSV file with headers\"\"\"\n","        try:\n","            if not os.path.exists(self.output_file):\n","                with open(self.output_file, 'w', newline='', encoding='utf-8') as f:\n","                    writer = csv.DictWriter(f, fieldnames=self.fieldnames)\n","                    writer.writeheader()\n","                print(f\"Created new CSV file: {self.output_file}\")\n","            else:\n","                print(f\"CSV file already exists: {self.output_file}\")\n","        except Exception as e:\n","            print(f\"Error setting up CSV: {str(e)}\")\n","\n","    def get_bid_listings(self):\n","        \"\"\"Fetch and parse all bid listings\"\"\"\n","        try:\n","            print(f\"Navigating to {self.base_url}\")\n","            self.driver.get(self.base_url)\n","            time.sleep(2)  # Wait for page to load\n","\n","            # Show closed bids checkbox\n","            checkbox = self.wait.until(EC.presence_of_element_located((By.ID, \"showAllBids\")))\n","            if not checkbox.is_selected():\n","                checkbox.click()\n","                time.sleep(2)\n","\n","            # Find all category headers\n","            headers = self.driver.find_elements(By.CLASS_NAME, \"bidsHeader\")\n","            if not headers:\n","                print(\"No bid categories found\")\n","                return []\n","\n","            bids = []\n","            for header in headers:\n","                try:\n","                    # Get category name\n","                    category = header.find_element(By.TAG_NAME, \"span\").text.strip()\n","                    if not category:\n","                        continue\n","\n","                    print(f\"\\nProcessing category: {category}\")\n","\n","                    # Get all bid items following this header until next header\n","                    next_element = header\n","                    while True:\n","                        try:\n","                            next_element = next_element.find_element(By.XPATH, \"following-sibling::div[contains(@class, 'listItemsRow')]\")\n","                            if 'bidsHeader' in next_element.get_attribute('class'):\n","                                break\n","\n","                            bid_data = self.parse_bid_item(next_element, category)\n","                            if bid_data:\n","                                bids.append(bid_data)\n","\n","                        except:\n","                            break\n","\n","                except Exception as e:\n","                    print(f\"Error processing category: {str(e)}\")\n","                    continue\n","\n","            print(f\"Found {len(bids)} bids\")\n","            return bids\n","\n","        except Exception as e:\n","            print(f\"Error fetching bid listings: {str(e)}\")\n","            return []\n","\n","    def save_bids(self, bids):\n","        \"\"\"Save bid data to CSV\"\"\"\n","        try:\n","            existing_bids = set()\n","            if os.path.exists(self.output_file):\n","                with open(self.output_file, 'r', encoding='utf-8') as f:\n","                    reader = csv.DictReader(f)\n","                    for row in reader:\n","                        existing_bids.add(f\"{row['Category']}-{row['Bid Title']}\")\n","\n","            new_bids = [bid for bid in bids if f\"{bid['Category']}-{bid['Bid Title']}\" not in existing_bids]\n","\n","            if new_bids:\n","                mode = 'w' if not os.path.exists(self.output_file) else 'a'\n","                with open(self.output_file, mode, newline='', encoding='utf-8') as f:\n","                    writer = csv.DictWriter(f, fieldnames=self.fieldnames)\n","                    if mode == 'w':\n","                        writer.writeheader()\n","                    writer.writerows(new_bids)\n","                print(f\"Added {len(new_bids)} new bids\")\n","            else:\n","                print(\"No new bids to add\")\n","\n","            # Download the CSV file\n","            files.download(self.output_file)\n","\n","        except Exception as e:\n","            print(f\"Error saving bids: {str(e)}\")\n","\n","    def run(self):\n","        \"\"\"Main execution method\"\"\"\n","        try:\n","            print(f\"Starting Yorba Linda bids crawler at {datetime.now()}\")\n","            self.setup_csv()\n","            bids = self.get_bid_listings()\n","            self.save_bids(bids)\n","            print(\"Crawler execution completed\")\n","        finally:\n","            if hasattr(self, 'driver'):\n","                self.driver.quit()"],"metadata":{"id":"NlSFTFwTIiNl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["crawler = YorbaLindaBidsCrawler()\n","crawler.run()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":231},"id":"KRfDEuoqLEjy","executionInfo":{"status":"ok","timestamp":1739162650005,"user_tz":480,"elapsed":26010,"user":{"displayName":"Ritunjay Murali","userId":"07921326813984298862"}},"outputId":"f8ffb238-a946-4963-c56a-844a68071b05"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Attempting to use system chromedriver...\n","Chrome driver initialized successfully\n","Starting Yorba Linda bids crawler at 2025-02-10 04:43:57.055538\n","Created new CSV file: yorba_linda_bids.csv\n","Navigating to https://www.yorbalindaca.gov/bids.aspx\n","\n","Processing category: Public Works\n","\n","Processing category: Yorba Linda RFPs\n","Found 19 bids\n","Added 19 new bids\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["download(\"download_f9cdf2f6-077d-4e89-bc26-eac1c1c4ccf4\", \"yorba_linda_bids.csv\", 6362)"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Crawler execution completed\n"]}]},{"cell_type":"markdown","source":["## Disclaimer\n","This tool accesses publicly available information only from official government websites. It respects robots.txt guidelines and implements responsible scraping practices with delays between requests."],"metadata":{"id":"Wi9vhs23IaGR"}}]}